{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libopf_py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8bd5dd162c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibopf_py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libopf_py'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import csv\n",
    "import gc\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from time import time\n",
    "import libopf_py\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv():\n",
    "    file = pd.read_csv(\"csv_dataset/dataframe.csv\", header=None, sep=';')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = read_csv()\n",
    "    X = df.iloc[1:86,1:137]\n",
    "    y = df.iloc[1:,137]\n",
    "    #X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "    benchmark(X, y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(data, target, n_samples):\n",
    "    list_n_samples = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    opf_results = np.zeros((len(list_n_samples), 4))\n",
    "    svm_results = np.zeros((len(list_n_samples), 4))\n",
    "    bayes_results = np.zeros((len(list_n_samples), 4))\n",
    "    linear_results = np.zeros((len(list_n_samples), 4))\n",
    "    sgd_results = np.zeros((len(list_n_samples), 4))\n",
    "    tree_results = np.zeros((len(list_n_samples), 4))\n",
    "\n",
    "    for i, size in enumerate(list_n_samples):\n",
    "        n_split = int(size * n_samples)\n",
    "        rand = np.random.permutation(n_samples)\n",
    "        random_data = data[rand]\n",
    "        random_label = target[rand]\n",
    "        data_train, data_test = random_data[:n_split], random_data[n_split:]\n",
    "        label_train, label_test = random_label[:n_split], random_label[n_split:]\n",
    "\n",
    "        def _opf():\n",
    "            label_train_32 = label_train.astype(np.int32)\n",
    "            label_test_32 = label_test.astype(np.int32)\n",
    "            O = libopf_py.OPF()\n",
    "            t = time()\n",
    "            O.fit(data_train, label_train_32)\n",
    "\n",
    "            opf_results[i, 3] = time() - t\n",
    "            t = time()\n",
    "            print(\"----------OPF------------\")\n",
    "            print(t)\n",
    "            predicted = O.predict(data_test)\n",
    "            opf_results[i, 0] = precision_score(label_test_32, predicted, average='binary')\n",
    "            opf_results[i, 1] = recall_score(label_test_32, predicted, average='binary')\n",
    "            opf_results[i, 2] = f1_score(label_test_32, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _svm():\n",
    "            clf = svm.SVC(C=1000, gamma='auto')\n",
    "            t = time()\n",
    "            print(\"-----------SVM-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            svm_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            svm_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            svm_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            svm_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _bayes():\n",
    "            clf = GaussianNB()\n",
    "            t = time()\n",
    "            print(\"-----------BAYES-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            bayes_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            bayes_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            bayes_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            bayes_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _linear():\n",
    "            clf = LogisticRegression(C=1, penalty='l2', solver='liblinear')\n",
    "            t = time()\n",
    "            print(\"-----------LINEAR-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            linear_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            linear_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            linear_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            linear_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _sgd():\n",
    "            clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000, tol=1e-3)\n",
    "            t = time()\n",
    "            print(\"-----------SGD-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            linear_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            sgd_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            sgd_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            sgd_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _tree():\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            t = time()\n",
    "            print(\"-----------TREE-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            tree_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            tree_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            tree_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            tree_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        _opf()\n",
    "        _svm()\n",
    "        _bayes()\n",
    "        _linear()\n",
    "        _sgd()\n",
    "        _tree()\n",
    "\n",
    "    pl.figure()\n",
    "    pl.plot(list_n_samples, opf_results[:, 2], label=\"OPF\")\n",
    "    pl.plot(list_n_samples, svm_results[:, 2], label=\"SVM RBF\")\n",
    "    pl.plot(list_n_samples, bayes_results[:, 2], label=\"Naive Bayes\")\n",
    "    pl.plot(list_n_samples, linear_results[:, 2], label=\"Logistic Regression\")\n",
    "    pl.plot(list_n_samples, sgd_results[:, 2], label=\"SGD\")\n",
    "    pl.plot(list_n_samples, tree_results[:, 2], label=\"Decision Trees\")\n",
    "    pl.legend(loc='lower right', prop=dict(size=8))\n",
    "    pl.xlabel(\"Training set size\")\n",
    "    pl.ylabel(\"F1 score\")\n",
    "    # pl.title(\"Precision\")\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "read_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
