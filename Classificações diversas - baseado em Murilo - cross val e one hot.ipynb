{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sara/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import libopf_py\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1      2      3      4      5      6      7      8      9      10   \\\n",
      "1691   82.0  212.0   83.0  264.0   87.0  316.0   93.0  367.0  102.0  417.0   \n",
      "1573   86.0  216.0   90.0  266.0   98.0  314.0  103.0  361.0  112.0  408.0   \n",
      "880    87.0  203.0   88.0  253.0   94.0  303.0   99.0  352.0  108.0  400.0   \n",
      "1405   71.0  223.0   75.0  274.0   84.0  324.0   91.0  373.0  105.0  421.0   \n",
      "1420   84.0  234.0   89.0  285.0   99.0  334.0  109.0  383.0  124.0  430.0   \n",
      "1123  101.0  215.0  103.0  265.0  109.0  314.0  114.0  362.0  122.0  410.0   \n",
      "273    97.0  228.0  101.0  276.0  108.0  324.0  115.0  372.0  127.0  419.0   \n",
      "41     99.0  213.0  102.0  264.0  110.0  314.0  117.0  363.0  128.0  412.0   \n",
      "194    97.0  214.0  101.0  264.0  108.0  313.0  114.0  362.0  125.0  409.0   \n",
      "1038   82.0  232.0   88.0  280.0   96.0  324.0  103.0  370.0  114.0  415.0   \n",
      "643    68.0  235.0   73.0  284.0   83.0  329.0   93.0  374.0  107.0  417.0   \n",
      "120    85.0  216.0   90.0  266.0   98.0  314.0  104.0  363.0  117.0  411.0   \n",
      "1227   94.0  204.0   99.0  254.0  107.0  304.0  113.0  354.0  125.0  402.0   \n",
      "1010   88.0  221.0   93.0  271.0  102.0  319.0  109.0  366.0  121.0  412.0   \n",
      "1855   90.0  211.0   92.0  262.0   98.0  310.0  103.0  359.0  113.0  408.0   \n",
      "687    90.0  211.0   94.0  261.0  103.0  311.0  109.0  360.0  121.0  407.0   \n",
      "1523   81.0  228.0   86.0  277.0   94.0  324.0  101.0  370.0  112.0  415.0   \n",
      "1908   74.0  216.0   78.0  270.0   86.0  322.0   96.0  372.0  109.0  424.0   \n",
      "206    92.0  211.0   96.0  263.0  105.0  313.0  112.0  362.0  124.0  411.0   \n",
      "621    73.0  224.0   80.0  274.0   91.0  321.0   99.0  369.0  113.0  416.0   \n",
      "1144   90.0  210.0   92.0  262.0   99.0  312.0  105.0  362.0  115.0  410.0   \n",
      "1449   85.0  223.0   87.0  271.0   92.0  319.0   95.0  367.0  105.0  414.0   \n",
      "483    97.0  207.0  100.0  256.0  106.0  305.0  111.0  354.0  123.0  401.0   \n",
      "901    82.0  226.0   87.0  277.0   95.0  324.0  103.0  372.0  115.0  419.0   \n",
      "1852   93.0  212.0   97.0  262.0  106.0  311.0  112.0  359.0  123.0  405.0   \n",
      "1099   92.0  228.0   98.0  278.0  108.0  326.0  116.0  374.0  128.0  421.0   \n",
      "1597   86.0  205.0   88.0  256.0   94.0  306.0   99.0  356.0  110.0  406.0   \n",
      "1165   94.0  218.0   97.0  268.0  105.0  316.0  111.0  364.0  122.0  411.0   \n",
      "1447   82.0  218.0   86.0  269.0   94.0  319.0  101.0  366.0  112.0  414.0   \n",
      "1490   63.0  223.0   65.0  273.0   69.0  321.0   72.0  368.0   82.0  414.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "1582   99.0  215.0  101.0  268.0  108.0  320.0  114.0  371.0  124.0  421.0   \n",
      "998    90.0  224.0   95.0  275.0  103.0  324.0  111.0  371.0  123.0  417.0   \n",
      "276    76.0  228.0   82.0  277.0   91.0  325.0  101.0  373.0  116.0  419.0   \n",
      "216    88.0  213.0   91.0  264.0   99.0  313.0  107.0  362.0  120.0  409.0   \n",
      "735    80.0  215.0   85.0  266.0   94.0  315.0  102.0  364.0  113.0  411.0   \n",
      "802    87.0  208.0   91.0  258.0   98.0  307.0  104.0  355.0  115.0  401.0   \n",
      "1807   86.0  219.0   93.0  269.0  104.0  318.0  113.0  366.0  127.0  413.0   \n",
      "887    96.0  208.0   99.0  259.0  106.0  308.0  112.0  357.0  123.0  406.0   \n",
      "147    93.0  222.0   96.0  272.0  104.0  322.0  110.0  371.0  123.0  419.0   \n",
      "1041  103.0  232.0  107.0  282.0  116.0  329.0  124.0  377.0  135.0  424.0   \n",
      "558    89.0  215.0   92.0  264.0   98.0  311.0  103.0  359.0  112.0  407.0   \n",
      "131    92.0  222.0   95.0  273.0  104.0  323.0  111.0  372.0  123.0  420.0   \n",
      "150    85.0  220.0   90.0  270.0   98.0  318.0  105.0  367.0  117.0  413.0   \n",
      "522    80.0  222.0   84.0  270.0   91.0  316.0   95.0  364.0  106.0  411.0   \n",
      "96     86.0  218.0   90.0  269.0   98.0  320.0  105.0  370.0  117.0  418.0   \n",
      "1845   79.0  211.0   83.0  260.0   90.0  307.0   96.0  355.0  108.0  403.0   \n",
      "1239   86.0  198.0   88.0  249.0   96.0  299.0  101.0  347.0  112.0  396.0   \n",
      "1237   85.0  200.0   88.0  250.0   95.0  299.0  100.0  348.0  111.0  396.0   \n",
      "344    80.0  214.0   83.0  262.0   90.0  309.0   94.0  357.0  105.0  405.0   \n",
      "1787   91.0  231.0   95.0  284.0  105.0  335.0  113.0  385.0  124.0  435.0   \n",
      "12     95.0  218.0   98.0  271.0  105.0  323.0  111.0  373.0  122.0  421.0   \n",
      "326    90.0  214.0   93.0  263.0  100.0  310.0  105.0  359.0  117.0  406.0   \n",
      "1221   88.0  221.0   92.0  272.0  100.0  321.0  107.0  371.0  119.0  418.0   \n",
      "108    95.0  204.0   98.0  255.0  106.0  305.0  113.0  355.0  125.0  404.0   \n",
      "915    89.0  220.0   93.0  270.0  100.0  318.0  107.0  366.0  119.0  412.0   \n",
      "1655   93.0  212.0   93.0  263.0   96.0  313.0   99.0  363.0  106.0  412.0   \n",
      "862    80.0  204.0   82.0  253.0   88.0  303.0   92.0  352.0  100.0  399.0   \n",
      "185    97.0  216.0  102.0  268.0  111.0  318.0  117.0  367.0  131.0  415.0   \n",
      "505    95.0  217.0   98.0  264.0  104.0  310.0  110.0  357.0  119.0  405.0   \n",
      "1359   94.0  208.0   93.0  255.0   95.0  300.0   95.0  347.0   99.0  395.0   \n",
      "\n",
      "      ...    128    129    130    131    132    133    134    135    136 137  \n",
      "1691  ...  422.0  287.0  440.0  257.0  431.0  243.0  431.0  230.0  429.0  21  \n",
      "1573  ...  390.0  313.0  407.0  278.0  409.0  260.0  409.0  242.0  406.0  21  \n",
      "880   ...  403.0  308.0  415.0  274.0  415.0  257.0  415.0  239.0  412.0  12  \n",
      "1405  ...  384.0  311.0  408.0  275.0  428.0  255.0  432.0  232.0  430.0  13  \n",
      "1420  ...  406.0  326.0  418.0  292.0  429.0  273.0  431.0  254.0  430.0  13  \n",
      "1123  ...  413.0  312.0  423.0  283.0  419.0  266.0  419.0  250.0  416.0  12  \n",
      "273   ...  393.0  336.0  395.0  295.0  401.0  275.0  403.0  255.0  402.0   2  \n",
      "41    ...  417.0  313.0  427.0  285.0  424.0  270.0  426.0  255.0  423.0   0  \n",
      "194   ...  413.0  330.0  412.0  291.0  411.0  273.0  412.0  255.0  410.0   0  \n",
      "1038  ...  392.0  307.0  406.0  274.0  407.0  257.0  408.0  240.0  407.0  12  \n",
      "643   ...  384.0  305.0  395.0  270.0  391.0  253.0  393.0  235.0  391.0   9  \n",
      "120   ...  390.0  321.0  402.0  283.0  420.0  264.0  423.0  244.0  421.0   0  \n",
      "1227  ...  395.0  331.0  398.0  284.0  420.0  262.0  422.0  240.0  419.0  13  \n",
      "1010  ...  404.0  320.0  408.0  283.0  411.0  265.0  412.0  246.0  409.0  12  \n",
      "1855  ...  408.0  314.0  420.0  283.0  424.0  265.0  426.0  247.0  422.0  22  \n",
      "687   ...  408.0  323.0  408.0  288.0  407.0  271.0  408.0  254.0  406.0   9  \n",
      "1523  ...  402.0  312.0  405.0  274.0  397.0  259.0  398.0  243.0  396.0  21  \n",
      "1908  ...  414.0  318.0  421.0  287.0  437.0  268.0  439.0  249.0  438.0  22  \n",
      "206   ...  415.0  318.0  417.0  286.0  416.0  271.0  418.0  256.0  417.0   0  \n",
      "621   ...  382.0  331.0  391.0  287.0  414.0  265.0  416.0  242.0  415.0   9  \n",
      "1144  ...  410.0  308.0  422.0  281.0  424.0  263.0  426.0  246.0  423.0  12  \n",
      "1449  ...  393.0  324.0  405.0  275.0  421.0  253.0  421.0  230.0  419.0  21  \n",
      "483   ...  409.0  324.0  406.0  285.0  407.0  268.0  409.0  251.0  406.0   2  \n",
      "901   ...  407.0  311.0  413.0  277.0  407.0  261.0  408.0  245.0  406.0  12  \n",
      "1852  ...  412.0  318.0  416.0  286.0  417.0  268.0  419.0  250.0  416.0  22  \n",
      "1099  ...  403.0  336.0  410.0  295.0  423.0  275.0  426.0  255.0  423.0  12  \n",
      "1597  ...  392.0  316.0  411.0  274.0  435.0  251.0  436.0  227.0  432.0  21  \n",
      "1165  ...  412.0  320.0  417.0  287.0  412.0  270.0  413.0  254.0  410.0  13  \n",
      "1447  ...  400.0  310.0  417.0  280.0  418.0  262.0  419.0  244.0  419.0  21  \n",
      "1490  ...  394.0  310.0  411.0  265.0  422.0  240.0  422.0  213.0  418.0  21  \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ..  \n",
      "1582  ...  414.0  310.0  429.0  284.0  425.0  269.0  426.0  254.0  425.0  21  \n",
      "998   ...  397.0  317.0  411.0  283.0  423.0  264.0  427.0  244.0  425.0  12  \n",
      "276   ...  383.0  333.0  393.0  294.0  412.0  272.0  415.0  250.0  413.0   2  \n",
      "216   ...  409.0  316.0  415.0  283.0  412.0  267.0  413.0  251.0  410.0   0  \n",
      "735   ...  393.0  319.0  404.0  282.0  419.0  262.0  421.0  241.0  418.0   9  \n",
      "802   ...  407.0  318.0  408.0  280.0  404.0  262.0  405.0  245.0  403.0  12  \n",
      "1807  ...  408.0  325.0  413.0  293.0  417.0  277.0  419.0  260.0  417.0  22  \n",
      "887   ...  405.0  320.0  416.0  289.0  415.0  272.0  416.0  255.0  414.0  12  \n",
      "147   ...  414.0  326.0  414.0  290.0  414.0  272.0  415.0  255.0  412.0   0  \n",
      "1041  ...  414.0  325.0  421.0  296.0  414.0  281.0  416.0  267.0  415.0  12  \n",
      "558   ...  381.0  326.0  398.0  283.0  420.0  260.0  421.0  238.0  417.0   9  \n",
      "131   ...  395.0  327.0  407.0  291.0  417.0  271.0  419.0  252.0  417.0   0  \n",
      "150   ...  392.0  331.0  399.0  288.0  419.0  266.0  421.0  244.0  419.0   0  \n",
      "522   ...  379.0  331.0  386.0  281.0  417.0  255.0  419.0  229.0  416.0   9  \n",
      "96    ...  398.0  316.0  410.0  280.0  426.0  261.0  428.0  242.0  425.0   0  \n",
      "1845  ...  405.0  315.0  402.0  274.0  403.0  258.0  403.0  240.0  401.0  22  \n",
      "1239  ...  402.0  304.0  411.0  274.0  413.0  256.0  414.0  239.0  411.0  13  \n",
      "1237  ...  403.0  304.0  412.0  274.0  411.0  256.0  412.0  238.0  409.0  13  \n",
      "344   ...  376.0  327.0  386.0  280.0  416.0  255.0  417.0  230.0  414.0   2  \n",
      "1787  ...  405.0  317.0  433.0  285.0  446.0  267.0  447.0  249.0  443.0  22  \n",
      "12    ...  402.0  319.0  418.0  285.0  430.0  266.0  432.0  247.0  428.0   0  \n",
      "326   ...  387.0  334.0  388.0  289.0  407.0  267.0  409.0  244.0  406.0   2  \n",
      "1221  ...  401.0  331.0  409.0  289.0  428.0  267.0  430.0  246.0  427.0  13  \n",
      "108   ...  410.0  317.0  416.0  286.0  416.0  270.0  418.0  254.0  415.0   0  \n",
      "915   ...  407.0  319.0  409.0  282.0  404.0  265.0  405.0  248.0  403.0  12  \n",
      "1655  ...  407.0  302.0  416.0  267.0  407.0  251.0  407.0  235.0  403.0  21  \n",
      "862   ...  395.0  307.0  405.0  270.0  407.0  249.0  407.0  228.0  403.0  12  \n",
      "185   ...  395.0  329.0  410.0  296.0  425.0  277.0  427.0  259.0  425.0   0  \n",
      "505   ...  387.0  317.0  395.0  275.0  404.0  255.0  405.0  235.0  403.0   9  \n",
      "1359  ...  384.0  309.0  401.0  264.0  410.0  243.0  409.0  222.0  405.0  13  \n",
      "\n",
      "[1924 rows x 137 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv_dataset/dataframe_7emocoes com numeros.csv\", header=None, sep=';')\n",
    "df = df.drop([0], axis=0)\n",
    "df = df.drop(columns=[0])\n",
    "df = shuffle(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[ 82. 212.  83. ... 431. 230. 429.]\n",
      " [ 86. 216.  90. ... 409. 242. 406.]\n",
      " [ 87. 203.  88. ... 415. 239. 412.]\n",
      " ...\n",
      " [ 97. 216. 102. ... 427. 259. 425.]\n",
      " [ 95. 217.  98. ... 405. 235. 403.]\n",
      " [ 94. 208.  93. ... 409. 222. 405.]]\n",
      "1924\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[0:1925,0:136]\n",
    "print(type(features))\n",
    "features = features.to_numpy()\n",
    "features = features.astype('float64')\n",
    "\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21. 21. 12. ...  0.  9. 13.]\n",
      "1924\n"
     ]
    }
   ],
   "source": [
    "labels = df.iloc[0:,136]\n",
    "labels = labels.to_numpy()\n",
    "labels = labels.astype('float64')\n",
    "\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(features)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1539 samples\n",
      "Test set: 385 samples\n"
     ]
    }
   ],
   "source": [
    "train_feat,test_feat,train_labels,test_labels = train_test_split(features,labels, test_size=0.20,random_state=42 )\n",
    "\n",
    "print (\"Training set:\", train_feat.shape[0], \"samples\")\n",
    "print (\"Test set:\", test_feat.shape[0], \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptações ao OPF.\n",
    "def opf(train_labels1, train_feat1, test_labels1, test_feat1):\n",
    "        \n",
    "    # OPF only supports 32 bits labels at the moment\n",
    "    label_train_32 = train_labels1.astype(np.int32)\n",
    "    label_test_32 = test_labels1.astype(np.int32)\n",
    "\n",
    "    O = libopf_py.OPF()\n",
    "\n",
    "    O.fit(train_feat1, label_train_32)\n",
    "\n",
    "    predicted = O.predict(test_feat1)\n",
    "    name = \"OPF\"\n",
    "    acc = accuracy_score(label_test_32, predicted)\n",
    "    \n",
    "    return acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1\n",
    "models = (SVC(kernel='linear', C=C, gamma='auto'),\n",
    "          SVC(kernel='rbf', gamma=0.5, C=C),\n",
    "          SVC(kernel='poly', degree=3, C=C, gamma='auto'),\n",
    "          KNeighborsClassifier(3),\n",
    "          DecisionTreeClassifier(max_depth=8),\n",
    "          RandomForestClassifier(max_depth=8, n_estimators=10, max_features=1),          \n",
    "          AdaBoostClassifier(),\n",
    "          GaussianNB(),\n",
    "         )\n",
    "\n",
    "names = [\"SVC with linear kernel\",\"SVC with RBF kernel\",\"SVC with polynomial (degree 3) kernel\",\n",
    "         \"K Nearest Neighbors\",\"Decision Tree\", \"Random Forest\", \"AdaBoost\",\"Naive Bayes\", \"OPF\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X, y):\n",
    "    #X_train = []\n",
    "    #X_test = []\n",
    "    #y_train = []\n",
    "    #y_test = []\n",
    "    \n",
    "    kf = KFold(n_splits = 8) # Define the split - number of folds \n",
    "    kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validatorprint(kf) KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "    matrix_acc = pd.DataFrame()\n",
    "    fold = []\n",
    "    medias = []\n",
    "    i = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        train_feat, test_feat = X[train_index], X[test_index]\n",
    "        train_labels, test_labels = y[train_index], y[test_index]\n",
    "    \n",
    "        for name, clf in zip(names, models):\n",
    "            clf.fit(train_feat,train_labels) #train each model\n",
    "            fold.append(clf.score(test_feat,test_labels)) #evaluate each model in the test set\n",
    "        res_opf = opf(train_labels, train_feat, test_labels, test_feat)\n",
    "        fold.append(res_opf)\n",
    "        \n",
    "        #print(fold)\n",
    "        data = pd.DataFrame([fold])\n",
    "        matrix_acc = matrix_acc.append(data)\n",
    "        fold = []\n",
    "    \n",
    "    return matrix_acc\n",
    "    \n",
    "        #X_test.append(X[test_index])   # Uso isso se quiser debugar e saber os folds.\n",
    "        #X_train.append(X[train_index])\n",
    "        #y_test.append(y[test_index])\n",
    "        #y_train.append(y[train_index])\n",
    "        \n",
    "    #return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_emotions(labels_num):\n",
    "    i = 0\n",
    "    labels = []\n",
    "    while (i < 1924):\n",
    "        if labels_num[i] == 0.0:\n",
    "            labels.append(\"neutro\") \n",
    "        if labels_num[i] == 2.0:\n",
    "            labels.append(\"alegria\")\n",
    "        if labels_num[i] == 9.0:\n",
    "            labels.append(\"surpresa\")\n",
    "        if labels_num[i] == 12.0:\n",
    "            labels.append(\"tristeza\")\n",
    "        if labels_num[i] == 13.0:\n",
    "            labels.append(\"medo\")\n",
    "        if labels_num[i] == 21.0:\n",
    "            labels.append(\"nojo\")\n",
    "        if labels_num[i] == 22.0:\n",
    "            labels.append(\"raiva\")\n",
    "        i += 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = kfold(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifiers:                    Accuracy (standard deviation)\n",
      "SVC with linear kernel                    0.784 (+/- 0.070) \n",
      "SVC with RBF kernel                       0.190 (+/- 0.056) \n",
      "SVC with polynomial (degree 3) kernel     0.797 (+/- 0.065) \n",
      "K Nearest Neighbors                       0.532 (+/- 0.036) \n",
      "Decision Tree                             0.490 (+/- 0.064) \n",
      "Random Forest                             0.491 (+/- 0.067) \n",
      "AdaBoost                                  0.460 (+/- 0.041) \n",
      "Naive Bayes                               0.421 (+/- 0.040) \n",
      "OPF                                       0.544 (+/- 0.041) \n"
     ]
    }
   ],
   "source": [
    "print (\"      Classifiers: \\t Accuracy (standard deviation)\".expandtabs(37))\n",
    "j = 0\n",
    "for j in range(9):\n",
    "    cl = matrix.iloc[0:,j] # separar todos os classificadores para depois fazer suas medias e desvios.\n",
    "    #print(cl)\n",
    "    #print(\"media\", cl.mean())\n",
    "    #print(\"desvio padrão\", cl.std())\n",
    "    print (\"{:41} {:.3f} (+/- {:.3f}) \".format(names[j], cl.mean(), cl.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir daqui vou fazer o One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.0   2.0   9.0   12.0  13.0  21.0  22.0\n",
      "0        0     0     0     0     0     1     0\n",
      "1        0     0     0     0     0     1     0\n",
      "2        0     0     0     1     0     0     0\n",
      "3        0     0     0     0     1     0     0\n",
      "4        0     0     0     0     1     0     0\n",
      "5        0     0     0     1     0     0     0\n",
      "6        0     1     0     0     0     0     0\n",
      "7        1     0     0     0     0     0     0\n",
      "8        1     0     0     0     0     0     0\n",
      "9        0     0     0     1     0     0     0\n",
      "10       0     0     1     0     0     0     0\n",
      "11       1     0     0     0     0     0     0\n",
      "12       0     0     0     0     1     0     0\n",
      "13       0     0     0     1     0     0     0\n",
      "14       0     0     0     0     0     0     1\n",
      "15       0     0     1     0     0     0     0\n",
      "16       0     0     0     0     0     1     0\n",
      "17       0     0     0     0     0     0     1\n",
      "18       1     0     0     0     0     0     0\n",
      "19       0     0     1     0     0     0     0\n",
      "20       0     0     0     1     0     0     0\n",
      "21       0     0     0     0     0     1     0\n",
      "22       0     1     0     0     0     0     0\n",
      "23       0     0     0     1     0     0     0\n",
      "24       0     0     0     0     0     0     1\n",
      "25       0     0     0     1     0     0     0\n",
      "26       0     0     0     0     0     1     0\n",
      "27       0     0     0     0     1     0     0\n",
      "28       0     0     0     0     0     1     0\n",
      "29       0     0     0     0     0     1     0\n",
      "...    ...   ...   ...   ...   ...   ...   ...\n",
      "1894     0     0     0     0     0     1     0\n",
      "1895     0     0     0     1     0     0     0\n",
      "1896     0     1     0     0     0     0     0\n",
      "1897     1     0     0     0     0     0     0\n",
      "1898     0     0     1     0     0     0     0\n",
      "1899     0     0     0     1     0     0     0\n",
      "1900     0     0     0     0     0     0     1\n",
      "1901     0     0     0     1     0     0     0\n",
      "1902     1     0     0     0     0     0     0\n",
      "1903     0     0     0     1     0     0     0\n",
      "1904     0     0     1     0     0     0     0\n",
      "1905     1     0     0     0     0     0     0\n",
      "1906     1     0     0     0     0     0     0\n",
      "1907     0     0     1     0     0     0     0\n",
      "1908     1     0     0     0     0     0     0\n",
      "1909     0     0     0     0     0     0     1\n",
      "1910     0     0     0     0     1     0     0\n",
      "1911     0     0     0     0     1     0     0\n",
      "1912     0     1     0     0     0     0     0\n",
      "1913     0     0     0     0     0     0     1\n",
      "1914     1     0     0     0     0     0     0\n",
      "1915     0     1     0     0     0     0     0\n",
      "1916     0     0     0     0     1     0     0\n",
      "1917     1     0     0     0     0     0     0\n",
      "1918     0     0     0     1     0     0     0\n",
      "1919     0     0     0     0     0     1     0\n",
      "1920     0     0     0     1     0     0     0\n",
      "1921     1     0     0     0     0     0     0\n",
      "1922     0     0     1     0     0     0     0\n",
      "1923     0     0     0     0     1     0     0\n",
      "\n",
      "[1924 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "y_oh = pd.get_dummies(labels) # aqui eu binarizo as labels e aplico o One Hot Encoding.\n",
    "print(y_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas próximas células foram feitas em teste para ver o que acontece quando tento classificar com 7 colunas de labels. Deu pra ver que os classificadores do scikit learn querem apenas uma coluna de label.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label = y_oh\n",
    "label = label.to_numpy()\n",
    "label = label.astype('float64')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (1683, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-537e59860942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-36f3c3259798>\u001b[0m in \u001b[0;36mkfold\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#evaluate each model in the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres_opf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m                         dtype=None)\n\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (1683, 7)"
     ]
    }
   ],
   "source": [
    "matrix = kfold(features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, se eu mando só uma coluna da matriz \"binarizada\" (y_oh), o resultado sai muito bom, até difícil de acreditar. Deve-se atentar para a ideia de mandar uma coluna binária de cada vez e depois fazer algum tipo de média ou deixar da forma que está (números puros das emoções - 0, 2, 9, 12, 13, 21, 22). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.0   2.0   9.0   12.0  13.0  21.0  22.0\n",
      "0        0     0     0     0     0     1     0\n",
      "1        0     0     0     0     0     1     0\n",
      "2        0     0     0     1     0     0     0\n",
      "3        0     0     0     0     1     0     0\n",
      "4        0     0     0     0     1     0     0\n",
      "5        0     0     0     1     0     0     0\n",
      "6        0     1     0     0     0     0     0\n",
      "7        1     0     0     0     0     0     0\n",
      "8        1     0     0     0     0     0     0\n",
      "9        0     0     0     1     0     0     0\n",
      "10       0     0     1     0     0     0     0\n",
      "11       1     0     0     0     0     0     0\n",
      "12       0     0     0     0     1     0     0\n",
      "13       0     0     0     1     0     0     0\n",
      "14       0     0     0     0     0     0     1\n",
      "15       0     0     1     0     0     0     0\n",
      "16       0     0     0     0     0     1     0\n",
      "17       0     0     0     0     0     0     1\n",
      "18       1     0     0     0     0     0     0\n",
      "19       0     0     1     0     0     0     0\n",
      "20       0     0     0     1     0     0     0\n",
      "21       0     0     0     0     0     1     0\n",
      "22       0     1     0     0     0     0     0\n",
      "23       0     0     0     1     0     0     0\n",
      "24       0     0     0     0     0     0     1\n",
      "25       0     0     0     1     0     0     0\n",
      "26       0     0     0     0     0     1     0\n",
      "27       0     0     0     0     1     0     0\n",
      "28       0     0     0     0     0     1     0\n",
      "29       0     0     0     0     0     1     0\n",
      "...    ...   ...   ...   ...   ...   ...   ...\n",
      "1894     0     0     0     0     0     1     0\n",
      "1895     0     0     0     1     0     0     0\n",
      "1896     0     1     0     0     0     0     0\n",
      "1897     1     0     0     0     0     0     0\n",
      "1898     0     0     1     0     0     0     0\n",
      "1899     0     0     0     1     0     0     0\n",
      "1900     0     0     0     0     0     0     1\n",
      "1901     0     0     0     1     0     0     0\n",
      "1902     1     0     0     0     0     0     0\n",
      "1903     0     0     0     1     0     0     0\n",
      "1904     0     0     1     0     0     0     0\n",
      "1905     1     0     0     0     0     0     0\n",
      "1906     1     0     0     0     0     0     0\n",
      "1907     0     0     1     0     0     0     0\n",
      "1908     1     0     0     0     0     0     0\n",
      "1909     0     0     0     0     0     0     1\n",
      "1910     0     0     0     0     1     0     0\n",
      "1911     0     0     0     0     1     0     0\n",
      "1912     0     1     0     0     0     0     0\n",
      "1913     0     0     0     0     0     0     1\n",
      "1914     1     0     0     0     0     0     0\n",
      "1915     0     1     0     0     0     0     0\n",
      "1916     0     0     0     0     1     0     0\n",
      "1917     1     0     0     0     0     0     0\n",
      "1918     0     0     0     1     0     0     0\n",
      "1919     0     0     0     0     0     1     0\n",
      "1920     0     0     0     1     0     0     0\n",
      "1921     1     0     0     0     0     0     0\n",
      "1922     0     0     1     0     0     0     0\n",
      "1923     0     0     0     0     1     0     0\n",
      "\n",
      "[1924 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "y_oh = pd.get_dummies(labels) # aqui eu binarizo as labels e aplico o One Hot Encoding.\n",
    "print(y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifiers:                    Accuracy (standard deviation)\n",
      "SVC with linear kernel                    0.949 (+/- 0.018) \n",
      "SVC with RBF kernel                       0.876 (+/- 0.033) \n",
      "SVC with polynomial (degree 3) kernel     0.954 (+/- 0.024) \n",
      "K Nearest Neighbors                       0.890 (+/- 0.036) \n",
      "Decision Tree                             0.867 (+/- 0.046) \n",
      "Random Forest                             0.877 (+/- 0.030) \n",
      "AdaBoost                                  0.901 (+/- 0.036) \n",
      "Naive Bayes                               0.682 (+/- 0.073) \n",
      "OPF                                       0.874 (+/- 0.042) \n",
      "      Classifiers:                    Accuracy (standard deviation)\n",
      "SVC with linear kernel                    0.955 (+/- 0.023) \n",
      "SVC with RBF kernel                       0.872 (+/- 0.046) \n",
      "SVC with polynomial (degree 3) kernel     0.948 (+/- 0.022) \n",
      "K Nearest Neighbors                       0.916 (+/- 0.040) \n",
      "Decision Tree                             0.906 (+/- 0.021) \n",
      "Random Forest                             0.891 (+/- 0.042) \n",
      "AdaBoost                                  0.927 (+/- 0.031) \n",
      "Naive Bayes                               0.775 (+/- 0.052) \n",
      "OPF                                       0.910 (+/- 0.027) \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "emotion = []\n",
    "for i in range(8):\n",
    "    label = y_oh.iloc[0:,i]\n",
    "    label = label.to_numpy()\n",
    "    matrix = kfold(features, label)\n",
    "    results(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(matrix1):\n",
    "    print (\"      Classifiers: \\t Accuracy (standard deviation)\".expandtabs(37))\n",
    "    j = 0\n",
    "    for j in range(9):\n",
    "        cl = matrix1.iloc[0:,j] # separar todos os classificadores para depois fazer suas medias e desvios.\n",
    "        #print(cl)\n",
    "        #print(\"media\", cl.mean())\n",
    "        #print(\"desvio padrão\", cl.std())\n",
    "        print (\"{:41} {:.3f} (+/- {:.3f}) \".format(names[j], cl.mean(), cl.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
