{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGray(img): # function that convert image to grayscale.\n",
    "\treturn cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(imag):\n",
    "\tlandmarks = []\n",
    "\tdetections = detector(imag, 1)\n",
    "    \n",
    "\tfor k,d in enumerate(detections): #For all detected face instances individually\n",
    "\t\tshape = predictor(imag, d) #Draw Facial Landmarks with the predictor class\n",
    "\t\txlist = []\n",
    "\t\tylist = []\n",
    "\t\tfor i in range(1,68): #Store X and Y coordinates in two lists\n",
    "\t\t\txlist.append(float(shape.part(i).x))\n",
    "\t\t\tylist.append(float(shape.part(i).y))\n",
    "\n",
    "\t\tfor x, y in zip(xlist, ylist): #Store all landmarks in one list in the format x1,y1,x2,y2,etc.\n",
    "\t\t\tlandmarks.append(x)\n",
    "\t\t\tlandmarks.append(y)\n",
    "            \n",
    "\tif len(detections) > 0:\n",
    "\t\treturn landmarks\n",
    "\telse: #If no faces are detected, return error message to other function to handle\n",
    "\t\tlandmarks = \"error\"\n",
    "\t\treturn landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFrames(pathIn, pathOut):\n",
    "\tdf = pd.DataFrame()\n",
    "\tos.mkdir(pathOut)\n",
    "\n",
    "\tcap = cv2.VideoCapture(pathIn)\n",
    "\tcount = 0\n",
    "\tbias = 50\n",
    "\twhile (cap.isOpened() and count<10): # o contador<10 serve para tirar apenas os 10 primeiros frames do video\n",
    "\n",
    "\t\t# Capture frame-by-frame\n",
    "\t\tret, frame = cap.read()\n",
    "\n",
    "\t\tif ret == True:\n",
    "\t\t\tprint('Read %d frame: ' % count, ret)\n",
    "\n",
    "\t\t\tframe = convertToGray(frame) # convert image to gray\n",
    "\t\t\t# uses the classifier HaarCascade to extract the faces.\n",
    "\t\t\thaar_face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\t\t\tfaces = haar_face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5) # detecta quantas faces ha na imagem\n",
    "\n",
    "\t\t\tfor (x,y,w,h) in faces: # Para cada\n",
    "\t\t\t\tcrop_img = frame[y-bias: y+h+bias, x-bias: x+w+bias]\n",
    "\n",
    "\t\t\tlandmark = get_landmarks(crop_img) # Aqui recebo lista com landmarks.\n",
    "\t\t\t#print(type(landmark)) # Podemos ver com isso que a variavel retornada pela funcao get_landmarks eh do tipo list.\n",
    "\t\t\t#print(len(landmark)) # Tamanho da lista\n",
    "\t\t\tarray = np.array([landmark])\n",
    "\t\t\tland_array = pd.DataFrame(array)\n",
    "\t\t\tdf = df.append(land_array)\n",
    "\t\t\t#print(df)\n",
    "\n",
    "\t\t\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\t\t\tclahe_image = clahe.apply(crop_img) # Aplicação do Clahe a imagem ja em cinza\n",
    "\t\t\tdetections = detector(clahe_image, 1)#Detect the faces in the image\n",
    "\t\t\tfor k,d in enumerate(detections): #For each detected face\n",
    "            \t\t\tshape = predictor(clahe_image, d) #Get coordinates\n",
    "            \t\t\tfor i in range(1,68): #There are 68 landmark points on each face\n",
    "                     \t\t\t#For each point, draw a red circle with thickness2 on the original frame\n",
    "                    \t\t\tcv2.circle(crop_img, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2)\n",
    "                                # Colocar as coordenadas em um DataFrame\n",
    "\n",
    "\t\t\tcv2.imwrite(os.path.join(pathOut, \"frame{:d}.jpg\".format(count)), crop_img)  # save crop_img as JPEG file\n",
    "\n",
    "\t\t\tcount += 1\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tprint(df)\n",
    "\t# When everything done, release the capture\n",
    "\tcap.release()\n",
    "\t#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame():\n",
    "\n",
    "\tdf = pd.DataFrame()\n",
    "\tprint(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\textractFrames('Em1_Fala1_CarolinaHolly.mp4', 'A10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 frame:  True\n",
      "Read 1 frame:  True\n",
      "Read 2 frame:  True\n",
      "Read 3 frame:  True\n",
      "Read 4 frame:  True\n",
      "Read 5 frame:  True\n",
      "Read 6 frame:  True\n",
      "Read 7 frame:  True\n",
      "Read 8 frame:  True\n",
      "Read 9 frame:  True\n",
      "    0      1      2      3      4      5      6      7      8      9    ...  \\\n",
      "0  88.0  263.0   96.0  312.0  103.0  360.0  115.0  408.0  138.0  450.0  ...   \n",
      "0  88.0  262.0   96.0  311.0  102.0  360.0  115.0  407.0  138.0  450.0  ...   \n",
      "0  91.0  267.0  100.0  316.0  106.0  365.0  119.0  413.0  143.0  456.0  ...   \n",
      "0  93.0  267.0  102.0  316.0  109.0  366.0  121.0  414.0  144.0  457.0  ...   \n",
      "0  90.0  264.0   98.0  313.0  106.0  362.0  118.0  410.0  142.0  453.0  ...   \n",
      "0  87.0  261.0   96.0  310.0  103.0  359.0  115.0  407.0  138.0  451.0  ...   \n",
      "0  89.0  269.0   97.0  319.0  104.0  368.0  117.0  416.0  140.0  460.0  ...   \n",
      "0  87.0  265.0   95.0  315.0  102.0  365.0  115.0  414.0  138.0  459.0  ...   \n",
      "0  86.0  265.0   95.0  315.0  102.0  365.0  115.0  413.0  138.0  458.0  ...   \n",
      "0  85.0  267.0   94.0  316.0  102.0  366.0  115.0  414.0  138.0  458.0  ...   \n",
      "\n",
      "     124    125    126    127    128    129    130    131    132    133  \n",
      "0  283.0  406.0  318.0  405.0  282.0  405.0  265.0  407.0  246.0  404.0  \n",
      "0  284.0  404.0  318.0  404.0  282.0  404.0  265.0  406.0  247.0  403.0  \n",
      "0  287.0  406.0  321.0  408.0  286.0  411.0  268.0  413.0  250.0  412.0  \n",
      "0  289.0  404.0  323.0  408.0  288.0  415.0  270.0  417.0  252.0  415.0  \n",
      "0  287.0  398.0  322.0  405.0  286.0  416.0  267.0  417.0  248.0  415.0  \n",
      "0  283.0  394.0  319.0  403.0  282.0  416.0  264.0  418.0  245.0  416.0  \n",
      "0  285.0  400.0  321.0  410.0  285.0  423.0  266.0  425.0  247.0  423.0  \n",
      "0  284.0  396.0  319.0  407.0  283.0  424.0  264.0  426.0  244.0  424.0  \n",
      "0  282.0  394.0  319.0  404.0  282.0  423.0  264.0  425.0  244.0  423.0  \n",
      "0  283.0  392.0  319.0  404.0  283.0  422.0  264.0  424.0  244.0  422.0  \n",
      "\n",
      "[10 rows x 134 columns]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
