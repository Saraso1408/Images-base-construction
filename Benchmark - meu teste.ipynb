{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sara/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import csv\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from time import time\n",
    "import libopf_py\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv():\n",
    "    file = pd.read_csv(\"csv_dataset/dataframe.csv\", header=None, sep=';')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = read_csv()\n",
    "    df = df.drop([0], axis=0)\n",
    "    df = df.drop(columns=[0])\n",
    "    X = df.iloc[1:665,1:137]\n",
    "    X = X.to_numpy()\n",
    "    X = X.astype('float64')\n",
    "    y = df.iloc[1:,136]\n",
    "    y = y.to_numpy()\n",
    "    y = y.astype('float64')\n",
    "    #X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "    benchmark(X, y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(data, target, n_samples):\n",
    "    list_n_samples = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    opf_results = np.zeros((len(list_n_samples), 4))\n",
    "    svm_results = np.zeros((len(list_n_samples), 4))\n",
    "    bayes_results = np.zeros((len(list_n_samples), 4))\n",
    "    linear_results = np.zeros((len(list_n_samples), 4))\n",
    "    sgd_results = np.zeros((len(list_n_samples), 4))\n",
    "    tree_results = np.zeros((len(list_n_samples), 4))\n",
    "\n",
    "    for i, size in enumerate(list_n_samples):\n",
    "        n_split = int(size * n_samples)\n",
    "        rand = np.random.permutation(n_samples)\n",
    "        random_data = data[rand]\n",
    "        random_label = target[rand]\n",
    "        data_train, data_test = random_data[:n_split], random_data[n_split:]\n",
    "        label_train, label_test = random_label[:n_split], random_label[n_split:]\n",
    "\n",
    "        def _opf():\n",
    "            label_train_32 = label_train.astype(np.int32)\n",
    "            label_test_32 = label_test.astype(np.int32)\n",
    "            O = libopf_py.OPF()\n",
    "            t = time()\n",
    "            O.fit(data_train, label_train_32)\n",
    "\n",
    "            opf_results[i, 3] = time() - t\n",
    "            t = time()\n",
    "            print(\"----------OPF------------\")\n",
    "            print(t)\n",
    "            predicted = O.predict(data_test)\n",
    "            opf_results[i, 0] = precision_score(label_test_32, predicted, average='binary')\n",
    "            opf_results[i, 1] = recall_score(label_test_32, predicted, average='binary')\n",
    "            opf_results[i, 2] = f1_score(label_test_32, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _svm():\n",
    "            clf = svm.SVC(C=1000, gamma='auto')\n",
    "            t = time()\n",
    "            print(\"-----------SVM-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            svm_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            svm_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            svm_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            svm_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _bayes():\n",
    "            clf = GaussianNB()\n",
    "            t = time()\n",
    "            print(\"-----------BAYES-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            bayes_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            bayes_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            bayes_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            bayes_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _linear():\n",
    "            clf = LogisticRegression(C=1, penalty='l2', solver='liblinear')\n",
    "            t = time()\n",
    "            print(\"-----------LINEAR-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            linear_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            linear_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            linear_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            linear_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _sgd():\n",
    "            clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000, tol=1e-3)\n",
    "            t = time()\n",
    "            print(\"-----------SGD-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            linear_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            sgd_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            sgd_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            sgd_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        def _tree():\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            t = time()\n",
    "            print(\"-----------TREE-----------\")\n",
    "            print(t)\n",
    "            clf.fit(data_train, label_train)\n",
    "            tree_results[i, 3] = time() - t\n",
    "            predicted = clf.predict(data_test)\n",
    "            tree_results[i, 0] = precision_score(label_test, predicted, average='binary')\n",
    "            tree_results[i, 1] = recall_score(label_test, predicted, average='binary')\n",
    "            tree_results[i, 2] = f1_score(label_test, predicted, average='binary')\n",
    "            gc.collect()\n",
    "\n",
    "        _opf()\n",
    "        _svm()\n",
    "        _bayes()\n",
    "        _linear()\n",
    "        _sgd()\n",
    "        _tree()\n",
    "\n",
    "    pl.figure()\n",
    "    pl.plot(list_n_samples, opf_results[:, 2], label=\"OPF\")\n",
    "    pl.plot(list_n_samples, svm_results[:, 2], label=\"SVM RBF\")\n",
    "    pl.plot(list_n_samples, bayes_results[:, 2], label=\"Naive Bayes\")\n",
    "    pl.plot(list_n_samples, linear_results[:, 2], label=\"Logistic Regression\")\n",
    "    pl.plot(list_n_samples, sgd_results[:, 2], label=\"SGD\")\n",
    "    pl.plot(list_n_samples, tree_results[:, 2], label=\"Decision Trees\")\n",
    "    pl.legend(loc='lower right', prop=dict(size=8))\n",
    "    pl.xlabel(\"Training set size\")\n",
    "    pl.ylabel(\"F1 score\")\n",
    "    # pl.title(\"Precision\")\n",
    "    pl.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217.  87. 268. ... 246. 422.   1.]\n",
      " [221.  94. 271. ... 250. 414.   1.]\n",
      " [224.  89. 274. ... 245. 433.   1.]\n",
      " ...\n",
      " [225.  88. 272. ... 236. 403.   5.]\n",
      " [220.  98. 268. ... 250. 396.   5.]\n",
      " [208.  91. 257. ... 240. 391.   5.]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      "----------OPF------------\n",
      "1563028877.1589339\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3ed025dbecc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ea9054ab7f36>\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5ba7378a4ddd>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(data, target, n_samples)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0m_opf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0m_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5ba7378a4ddd>\u001b[0m in \u001b[0;36m_opf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mopf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mopf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mopf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_test_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1047\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
