{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sara/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import numpy\n",
    "import libopf_py\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      "\n",
      "[[218.  99. 268. ... 253. 410.   0.]\n",
      " [214.  87. 267. ... 246. 431.   0.]\n",
      " [216.  89. 267. ... 245. 422.   0.]\n",
      " ...\n",
      " [218.  84. 266. ... 244. 409.  22.]\n",
      " [213.  79. 261. ... 238. 402.  22.]\n",
      " [202.  75. 251. ... 233. 394.  22.]]\n",
      "n samples: \n",
      "\n",
      "965\n",
      "target:  [ 2.  9. 13. 21. 12. 13.  2.  0. 13. 21.  0. 21. 22. 22.  2.  0.  2. 13.\n",
      "  2.  9. 21.  0. 13. 13. 21.  0.  0.  9. 12.  0.  2.  0.  9.  2. 13. 12.\n",
      "  9.  9.  2. 13.  9. 21. 12. 12.  2. 12. 13.  0. 12.  2. 21.  2. 21. 12.\n",
      " 21.  9. 22. 21.  0. 22.  2. 22. 21. 21. 13. 12. 12. 12. 12.  2. 22.  0.\n",
      "  0.  0. 12.  2. 12. 22.  2.  9. 21. 13. 12. 22.  2. 13. 12. 21. 12. 21.\n",
      "  0.  9.  9. 13. 21. 13.  9.  2.  9.  9.  2.  0. 21.  0.  9. 12. 12. 22.\n",
      " 22.  2.  9. 21. 13. 13. 12.  9.  0. 12.  2.  9. 22. 13.  0.  2.  0.  0.\n",
      "  2.  9. 12. 12. 12. 21.  2. 21.  0. 21. 12. 13.  9. 13.  0.  9.  9.  2.\n",
      "  9.  9. 13. 12. 12.  9. 13.  9. 13.  9.  2.  2.  9. 21.  9.  9. 21. 22.\n",
      " 13.  9. 13.  9.  2. 22. 12.  9. 22. 22. 13. 22. 12. 12.  9.  9. 12.  9.\n",
      "  9. 22. 22. 13. 13.  9. 13.  0. 22. 21. 22. 12.  9. 12.  9. 12. 12. 12.\n",
      "  0. 22. 22.  9. 13. 13.  9.  9. 12.  2.  9. 13. 21. 21. 21. 12. 21.  2.\n",
      " 13.  2. 12. 13.  9.  2.  0.  0. 13. 21.  9. 13.  9.  2. 13.  0.  9.  9.\n",
      "  9. 21.  2. 13. 21.  9. 21.  9.  2.  0. 21. 13.  0. 13. 12.  9.  0. 12.\n",
      " 13.  9.  0. 12. 21. 21. 22.  9. 21. 22. 12.  9. 22.  2.  9. 22. 21. 22.\n",
      " 21. 22.  0. 13.  9. 12. 21. 22.  9. 22.  9. 12. 22.  2.  0. 21.  2. 12.\n",
      " 22. 12.  2.  9. 13.  2. 13.  9. 21. 12.  2. 12.  9.  2. 22.  2. 21.  9.\n",
      " 12. 22. 12.  9. 12.  9.  9.  2. 13. 21. 22. 12. 21. 22. 22.  0.  0. 12.\n",
      " 22. 21. 12. 13. 13. 13.  9.  0.  0. 21. 12. 12.  9. 12.  2. 22.  9. 12.\n",
      "  0. 12. 12. 21. 21. 12. 22. 21.  2.  0. 22.  0.  0.  9. 13.  2. 12. 12.\n",
      "  2. 12. 12. 21.  0. 22. 13. 13. 22. 12.  9.  0. 21.  2. 13. 12. 22.  9.\n",
      " 12. 21. 13. 13. 22. 13. 13.  0. 21. 21. 21. 12.  9. 22. 13. 13. 12. 12.\n",
      " 13.  9. 21. 21. 22.  0. 12. 12.  9. 12. 21. 21.  2. 21. 12.  9.  9. 21.\n",
      " 21.  0. 12.  0.  9. 12. 13. 13.  2. 22. 12. 22. 13.  2.  2. 12. 13.  2.\n",
      "  9. 12.  0.  2.  0.  2. 21. 12.  9.  9.  2. 21.  2.  9. 12.  9.  9. 22.\n",
      "  2.  2. 22.  9.  2.  0. 12. 13. 22. 12.  2.  0. 22.  9. 12. 21.  2. 12.\n",
      " 13.  0. 22.  2. 13.  0. 21.  0.  0. 21. 13. 12. 21.  0.  9.  9.  0.  2.\n",
      " 21.  9.  2. 22. 21. 12.  9. 22. 12.  9.  0. 12.  2. 22. 13. 12. 12. 13.\n",
      "  9.  9.  0. 12.  2. 13. 12.  9.  9.  0.  0.  9. 22. 13.  2.  0. 12.  9.\n",
      "  2. 21. 21. 12. 13.  9. 21. 22.  0.  9. 13.  0. 22. 21. 12.  2.  9. 12.\n",
      "  2. 13.  0. 13. 21. 12. 21. 12. 12. 21. 21. 12. 13. 21.  9.  0.  0. 12.\n",
      "  0.  2.  2.  9.  2. 22.  2.  0. 22. 21.  2. 12.  2. 12.  0.  2. 12.  2.\n",
      "  0.  9. 12. 22. 12. 22. 13.  2. 21.  9. 12. 12. 21. 21. 21.  2.  2.  9.\n",
      " 22.  0.  9. 12. 13.  2. 13. 21. 22.  9.  9. 12. 13. 13. 21.  9. 21.  2.\n",
      " 12.  9.  2. 21. 21.  9.  2. 21. 12. 13.  0. 21. 22. 13. 13.  9. 12.  9.\n",
      " 12. 21.  0.  2.  9. 22. 12. 13. 22. 21. 22. 13.  9. 22. 22. 12. 22. 22.\n",
      " 22. 12.  0.  2. 21. 22.  2. 13.  0.  9.  9. 12. 12. 21. 13. 21. 12. 12.\n",
      "  2.  0. 12.  9. 21.  2.  9.  0.  9. 13. 13. 13. 22. 12.  0.  9.  0. 21.\n",
      " 13. 13. 21. 12. 12.  2.  2. 12.  0.  0. 13.  2. 22.  2.  9.  2. 13. 21.\n",
      " 12. 21.  2. 22. 21. 13. 12.  2.  2. 21.  0.  0. 22.  9.  9.  9.  0. 13.\n",
      " 12. 13. 13. 12. 21. 21. 12.  0. 12.  2. 13. 21. 13. 21. 13.  2. 12.  2.\n",
      "  9.  0.  0. 12.  0. 22.  2. 21. 22. 21. 12. 21. 13. 21. 12. 21. 13. 13.\n",
      " 12.  0. 22. 12.  9.  0. 21.  0. 21. 21.  0. 12. 21.  9. 22. 21. 21.  0.\n",
      " 12.  2. 13. 12. 22.  2. 21.  0.  9. 12. 12.  0.  9.  9. 22. 22. 21.  0.\n",
      " 13.  0. 21. 22.  0.  2. 22.  2.  0. 12. 21. 12.  0.  9. 12.  2. 13.  0.\n",
      " 22. 13. 12. 13.  0. 21.  9. 13. 13. 21.  2.  2.  9.  9. 22. 13.  9. 13.\n",
      " 13. 21.  0.  0.  9.  9.  9.  2. 21. 21.  0. 12.  0. 12.  2. 12.  9. 12.\n",
      " 12. 12.  9.  2. 22.  9.  0.  2. 21. 12.  2.  9.  2. 13.  9. 22.  9. 22.\n",
      " 13. 12.  0. 12.  9.  9. 13. 12. 13. 12. 22. 12. 21. 13. 13. 21.  9. 21.\n",
      " 12.  0. 12. 22. 22. 21. 22. 21.  2.  2. 21.  2.  2. 12. 13. 22. 21. 22.\n",
      " 21. 12.  9.  2. 12. 12.  0. 13.  0.  2. 22.  0.  9. 12. 12.  0. 21.  0.\n",
      " 13. 13.  9. 21.  0.  0. 12. 13. 12.  9. 22. 13. 12.  0. 13. 13. 12. 13.\n",
      " 12.  2. 22. 12. 12. 13. 13. 22. 12. 21. 22. 12.  0. 21. 12.  9.  9. 22.\n",
      " 21. 12. 12. 13. 13. 13.  2.  9. 21. 12.  9.]\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "#digits = datasets.load_digits()\n",
    "#print(\"digits:   ---->>>> \", digits)\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "\n",
    "#n_samples = len(digits.images)\n",
    "#data = digits.images.reshape((n_samples, -1))\n",
    "#print(\"data: \\n\")\n",
    "#print(data)\n",
    "#print(\"n samples: \\n\")\n",
    "#print(n_samples)\n",
    "#print(len(data))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"csv_dataset/dataframe.csv\", header=None, sep=';')\n",
    "df = df.drop([0], axis=0)\n",
    "df = df.drop(columns=[0])\n",
    "data = df.iloc[1:2975,1:137]\n",
    "data = data.to_numpy()\n",
    "data = data.astype('float64')\n",
    "target = df.iloc[1:,136]\n",
    "target = target.to_numpy()\n",
    "target = target.astype('float64')\n",
    "n_samples = len(data)\n",
    "\n",
    "random.shuffle(target)\n",
    "random.shuffle(target)\n",
    "\n",
    "# Debugs\n",
    "print(\"data: \\n\")\n",
    "print(data)\n",
    "print(\"n samples: \\n\")\n",
    "print(n_samples)\n",
    "print(\"target: \", target)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(split):\n",
    "    n_split = int(split * n_samples)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Split: %3.2f\" % split)\n",
    "    print(\"Size: %d, Classifying Size: %d, Testing Size: %d\" % (n_samples, n_split, n_samples - n_split))\n",
    "\n",
    "    rand = numpy.random.permutation(n_samples)\n",
    "\n",
    "    #print(data)\n",
    "    #print(target)\n",
    "    \n",
    "    random_data = data[rand]\n",
    "    random_label = target[rand]\n",
    "\n",
    "    data_train, data_test = random_data[:n_split], random_data[n_split:]\n",
    "    label_train, label_test = random_label[:n_split], random_label[n_split:]\n",
    "\n",
    "    print(\"-\" * 20, \"OPF\", \"-\" * 20)\n",
    "\n",
    "    def opf():\n",
    "        \n",
    "        # OPF only supports 32 bits labels at the moment\n",
    "        label_train_32 = label_train.astype(numpy.int32)\n",
    "        label_test_32 = label_test.astype(numpy.int32)\n",
    "\n",
    "        O = libopf_py.OPF()\n",
    "\n",
    "        t = time.time()\n",
    "        O.fit(data_train, label_train_32)\n",
    "        #    O.fit(data_train_32, label_train_32, learning=\"agglomerative\", split=0.8)\n",
    "        print(\"OPF: time elapsed in fitting: %f secs\" % (time.time() - t))\n",
    "\n",
    "        t = time.time()\n",
    "        predicted = O.predict(data_test)\n",
    "        print(\"predicted: \\n\", predicted)\n",
    "        print(\"label_test: \\n\", label_test)\n",
    "        print(\"OPF: time elapsed in predicting: %f secs\" % (time.time() - t))\n",
    "\n",
    "        print(\"Classification report for OPF:\\n%s\\n\" % (classification_report(label_test_32, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % confusion_matrix(label_test_32, predicted))\n",
    "        \n",
    "        acc_opf = accuracy_score(label_test_32, predicted)\n",
    "        print(\"acuracia:\", acc_opf)\n",
    "\n",
    "    opf()\n",
    "\n",
    "    print(\"-\" * 20, \"SVM\", \"-\" * 20)\n",
    "\n",
    "    def _svm():\n",
    "        clf = SVC(gamma='auto')\n",
    "\n",
    "        t = time.time()\n",
    "        clf.fit(data_train, label_train)\n",
    "        print(\"SVM: time elapsed in fitting: %f secs\" % (time.time() - t))\n",
    "\n",
    "        t = time.time()\n",
    "        predicted = clf.predict(data_test)\n",
    "        print(\"predicted: \\n\", predicted)\n",
    "        print(\"label_test: \\n\", label_test)\n",
    "        print(\"tamanhos do predicted e do label_test: \", len(predicted), len(label_test))\n",
    "        print(\"SVM: time elapsed in predicting: %f secs\" % (time.time() - t))\n",
    "\n",
    "        print(\"Classification report for SVM:\\n%s\\n\" % (classification_report(label_test, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % confusion_matrix(label_test, predicted))\n",
    "        \n",
    "        # aqui eu vou calcular a acur√°cia.\n",
    "        acc_svm = accuracy_score(label_test, predicted)\n",
    "        print(\"acuracia:\", acc_svm)\n",
    "\n",
    "    _svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Split: 0.80\n",
      "Size: 965, Classifying Size: 772, Testing Size: 193\n",
      "-------------------- OPF --------------------\n",
      "OPF: time elapsed in fitting: 0.073668 secs\n",
      "predicted: \n",
      " [ 9 13 21 22  0  0  2 22 21 22 22 21 22  9  9  9 13  9  0 12 12 21 13 21\n",
      "  0 22 12 12 12  2 13 13  0 12 13  0 12 12  2  0 22  9 22 13  0  2 12 21\n",
      " 12  0 13 22 21 12 12  2  2  0 13 22 12  0  9 12 12 22 21 21 13 22 13 21\n",
      " 13 21 21 12 22  0 21  2 12 21  2  0  0 12 12  9 12  9  9 21 21  0 21  9\n",
      " 13  9  0 13  0  0 13 13 21  9 12 12 13 13 22 12  0 12 12 12  9 12 21  9\n",
      " 12 21  2 12  0 21  0 12  9  0  0 21  9 12  9 13  0 22 21 21  2  2 21 22\n",
      " 12  0 12 13 12 13 21  2  9 12  0  0  2 12 22  2  2 21 12  0 12 12 12  2\n",
      "  2 13 21 12  0  0 21  9  2 13  9 21 12  9  2 12  0 22 12  0  2  2 12 13\n",
      " 12]\n",
      "label_test: \n",
      " [12.  2. 13. 12. 21.  9. 12. 21.  2. 21.  9.  0.  2. 21.  2.  9. 21.  9.\n",
      " 21.  9.  2.  2. 12.  9. 13.  2.  2.  2. 12. 22.  0. 13.  0.  9. 12.  0.\n",
      " 13. 22.  9.  9. 21. 13.  2.  9.  9. 12.  9.  9. 21. 13. 13. 12.  9. 12.\n",
      " 13.  2. 13. 12.  9.  9. 13. 12.  9. 13.  9. 21. 12.  0.  9.  9.  2.  9.\n",
      "  0. 22.  2. 13. 22. 12. 22. 21.  2. 22.  0. 22.  0. 12.  0. 13. 21. 12.\n",
      " 12.  2. 22. 13. 13. 13.  9.  2. 13. 22. 13.  0.  9.  0. 21. 21. 22. 22.\n",
      " 12. 13.  2.  9. 22. 12. 22. 12. 21.  9.  9.  0.  9.  9. 22.  9. 12.  2.\n",
      "  0. 13. 13. 12.  0.  2. 12.  0. 13.  2.  2. 12. 13. 21.  9.  9.  9. 13.\n",
      "  9. 12.  2. 12. 12. 21. 12. 22. 21.  9. 21. 12. 12.  9. 13. 21. 21. 12.\n",
      " 12. 21. 13. 12. 21. 22.  0.  9.  9.  9. 22. 22.  9. 13.  0. 22. 12.  9.\n",
      " 12.  9.  2.  2. 12. 13. 22.  0. 21. 12.  9. 12. 12.]\n",
      "OPF: time elapsed in predicting: 0.013977 secs\n",
      "Classification report for OPF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.39      0.28        18\n",
      "           2       0.10      0.08      0.09        24\n",
      "           9       0.18      0.10      0.12        42\n",
      "          12       0.22      0.26      0.24        38\n",
      "          13       0.12      0.11      0.12        28\n",
      "          21       0.07      0.09      0.08        23\n",
      "          22       0.06      0.05      0.05        20\n",
      "\n",
      "   micro avg       0.15      0.15      0.15       193\n",
      "   macro avg       0.14      0.15      0.14       193\n",
      "weighted avg       0.15      0.15      0.14       193\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 7  3  1  2  3  2  0]\n",
      " [ 1  2  2  6  3  6  4]\n",
      " [ 3  3  4 13  6 10  3]\n",
      " [ 8  4  5 10  5  3  3]\n",
      " [ 5  1  6  7  3  3  3]\n",
      " [ 4  4  4  3  2  2  4]\n",
      " [ 4  4  0  5  2  4  1]]\n",
      "acuracia: 0.15025906735751296\n",
      "-------------------- SVM --------------------\n",
      "SVM: time elapsed in fitting: 0.245569 secs\n",
      "predicted: \n",
      " [12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.]\n",
      "label_test: \n",
      " [12.  2. 13. 12. 21.  9. 12. 21.  2. 21.  9.  0.  2. 21.  2.  9. 21.  9.\n",
      " 21.  9.  2.  2. 12.  9. 13.  2.  2.  2. 12. 22.  0. 13.  0.  9. 12.  0.\n",
      " 13. 22.  9.  9. 21. 13.  2.  9.  9. 12.  9.  9. 21. 13. 13. 12.  9. 12.\n",
      " 13.  2. 13. 12.  9.  9. 13. 12.  9. 13.  9. 21. 12.  0.  9.  9.  2.  9.\n",
      "  0. 22.  2. 13. 22. 12. 22. 21.  2. 22.  0. 22.  0. 12.  0. 13. 21. 12.\n",
      " 12.  2. 22. 13. 13. 13.  9.  2. 13. 22. 13.  0.  9.  0. 21. 21. 22. 22.\n",
      " 12. 13.  2.  9. 22. 12. 22. 12. 21.  9.  9.  0.  9.  9. 22.  9. 12.  2.\n",
      "  0. 13. 13. 12.  0.  2. 12.  0. 13.  2.  2. 12. 13. 21.  9.  9.  9. 13.\n",
      "  9. 12.  2. 12. 12. 21. 12. 22. 21.  9. 21. 12. 12.  9. 13. 21. 21. 12.\n",
      " 12. 21. 13. 12. 21. 22.  0.  9.  9.  9. 22. 22.  9. 13.  0. 22. 12.  9.\n",
      " 12.  9.  2.  2. 12. 13. 22.  0. 21. 12.  9. 12. 12.]\n",
      "tamanhos do predicted e do label_test:  193 193\n",
      "SVM: time elapsed in predicting: 0.034106 secs\n",
      "Classification report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        18\n",
      "         2.0       0.00      0.00      0.00        24\n",
      "         9.0       0.00      0.00      0.00        42\n",
      "        12.0       0.20      1.00      0.33        38\n",
      "        13.0       0.00      0.00      0.00        28\n",
      "        21.0       0.00      0.00      0.00        23\n",
      "        22.0       0.00      0.00      0.00        20\n",
      "\n",
      "   micro avg       0.20      0.20      0.20       193\n",
      "   macro avg       0.03      0.14      0.05       193\n",
      "weighted avg       0.04      0.20      0.06       193\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 0  0  0 18  0  0  0]\n",
      " [ 0  0  0 24  0  0  0]\n",
      " [ 0  0  0 42  0  0  0]\n",
      " [ 0  0  0 38  0  0  0]\n",
      " [ 0  0  0 28  0  0  0]\n",
      " [ 0  0  0 23  0  0  0]\n",
      " [ 0  0  0 20  0  0  0]]\n",
      "acuracia: 0.19689119170984457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
